{
    "contents" : "### Analysis\n\n#Explore terms in the documents: delete sparse ones (weird symbols...) and maybe some of high ocurrence ones\nfreq <- colSums(as.matrix(dtms))\nlength(freq)\nord <- order(freq)\nhist(prueba,1000)\n# most and less common words\nfreq[tail(ord, 20)]\nfreq[head(ord)]\n\n#########################################################################################################\n###################################### SUMMARIZING #######################################################\n#########################################################################################################\n\n\n\n## Explore some words with high ocurrence that are not relevant: also, came, first, must...\nfindFreqTerms(dtm, 3000)\n\n### Remove sparse terms\ndtms <- removeSparseTerms(dtm, 0.1) # This makes a matrix that is 10% empty space, maximum.\n# Weight terms as tf-idf\nlibrary(tm)\ndtm_tfxidf <- weightTfIdf(dtm)\ndtms_tfxidf <- weightTfIdf(dtms)\n\n\n\n#########################################################################################################\n###################################### WORD CLOUD #######################################################\n#########################################################################################################\n\nlibrary(wordcloud)\nlibrary(RColorBrewer)\nWordFrec.sort <- sort(colSums(m), decreasing = T)\nWordFrec.sort <- sort(m[1,], decreasing = T)\nset.seed(NULL)\npal2 <- brewer.pal(8,\"Dark2\")\npng(\"wordcloud_packages.png\", width=1280,height=800)\n#grayLevels <- gray( (WordFrec.sort + 10) / (max(WordFrec.sort) + 10))\nwordcloud(words=names(WordFrec.sort), freq=WordFrec.sort, min.freq=50,\n                        random.order=F, max.words = Inf,\n                        scale=c(5,.2),rot.per=.15, colors=pal2)\ndev.off()\n\n?wordcloud\npng(\"wordcloud_packages.png\", width=1280,height=800)\nwordcloud(ap.d$word,ap.d$freq, scale=c(8,.2),min.freq=3,\n          max.words=Inf, random.order=FALSE, colors=pal2)\n\n\n#########################################################################################################\n############################### HIERARCHICAL CLUSTERING #################################################\n#########################################################################################################\n\n#convert dtm to matrix\nm <- as.matrix(dtms)\nm_tfidf <- as.matrix(dtms_tfxidf)\nm_short_tfidf <- as.matrix(dtms_tfxidf)\n# Name the documents as the books\nrownames(m) <- BookNamesShorter\nrownames(m_tfidf) <- BookNamesShorter\nrownames(m_short_tfidf) <- BookNamesShortest\n\n# #shorten rownames for display purposes\n# rownames(m) <- paste(substring(rownames(m),1,3),rep('..',nrow(m)),\n#                       substring(rownames(m), nchar(rownames(m))-12,nchar(rownames(m))-4))\n\n# Distance matrix\ndistMatrix <- dist(scale(m))\n#run hierarchical clustering using Ward’s method\ngroups <- hclust(distMatrix,method='ward.D')\n#plot dendogram, use hang to ensure that labels fall below tree\nplot(groups, hang=-1, main='Hierarchical Clustering: Euler distance')\nrect.hclust(groups,k=2)\n\n############### TRY WITH DIFFERENT METHODS!!!\n\n# Cosine distance matrix: better results\nlibrary(proxy)\ncosMatrix <- dist(m, method=\"cosine\")\nhc <- hclust(cosMatrix, method=\"average\")\nplot(hc)\n\nheatmap(as.matrix(cosMatrix))\nheatmap(as.matrix(distMatrix))\n\ncosMatrix_tfidf <- dist(m_tfidf,method='cosine')\ncosMatrix_short_tfidf <- dist(m_short_tfidf,method='cosine')\n\nhc2 <- hclust(cosMatrix_tfidf, method='average')\nplot(hc2, main='Hierarchical Clustering', xlab = '', ylab = '', sub='')\n\n\n\n# \n# \n# ###################################################################################\n# # Convert into sparse matrix from \"Matrix\" package\n# matrix <- Matrix::sparseMatrix(i = dtm$i, j = dtm$j, x = dtm$v,\n#                           dims = c(dtm$nrow, dtm$ncol)) \n# \n# # Normalise lengths of documents\n# row_norms <- sqrt(rowSums(matrix ^ 2))\n# row_norms <- t(crossprod(sign(matrix), Diagonal(x = row_norms)))\n# row_norms@x <- 1/row_norms@x\n# m_norm <- matrix * row_norms\n# \n# # Finally, we can find cosine similarity\n# sim <- tcrossprod(m_norm)\n# # colnames(sim) <- metadata$shortname\n# # rownames(sim) <- metadata$shortname\n# dissim <- 1 - sim\n# ###################################################################################\n# \n# \n\n\n#########################################################################################################\n#################################### K-MEANS CLUSTERING #################################################\n#########################################################################################################\n\n# #k means algorithm, 6 clusters, 100 starting configurations\n# kfit <- kmeans(distMatrix, 6, nstart=100)\n# #plot – need library cluster\n# library(cluster)\n# clusplot(m, kfit$cluster, color=T, shade=T, labels=2, lines=0)\n\n# First normalize distances\nnorm_eucl <- function(m_tfidf) m_tfidf/apply(m_tfidf, MARGIN=1, FUN=function(x) sum(x^2)^.5)\nm_norm <- norm_eucl(m_tfidf)\n\nnorm_eucl <- function(m) m/apply(m, MARGIN=1, FUN=function(x) sum(x^2)^.5)\nm_norm <- norm_eucl(m)\n\n### cluster into 6 clusters\ncl <- kmeans(m_norm, 6)\ntable(cl$cluster)\n### show clusters using the first 2 principal components\nplot(prcomp(m_norm)$x, col=cl$cl, cex = 2, pch = 21, bg = cl$cl, main='k-means')\n# Add labels to the points \ntext(prcomp(m_norm)$x, BookNamesShort)\n\n\n\n\n#kmeans – determine the optimum number of clusters (elbow method)\n#look for “elbow” in plot of summed intra-cluster distances (withinss) as fn of k\nwss <- 2:23\nfor (i in 2:23) wss[i] <- sum(kmeans(distMatrix,centers=i,nstart=25)$withinss)\nplot(2:23, wss[2:23], type='b', xlab='Number of Clusters',ylab='Within groups sum of squares')\n\n\n\n# \n# #k means algorithm, 2 clusters, 100 starting configurations\n# kfit <- kmeans(distMatrix, 6, nstart=100)\n# #plot – need library cluster\n# library(cluster)\n# clusplot(m, kfit$cluster, color=T, shade=T, labels=2, lines=0)\n\n\n#########################################################################################################\n#################################### MultiDimensional Scaling #################################################\n#########################################################################################################\n\nfit <- cmdscale(distMatrix, eig = TRUE, k = 2)\nx <- fit$points[, 1]\ny <- fit$points[, 2]\n\nplot(x, y, pch = 19, xlim = range(x) + c(0, 600), main ='MultiDimensional Scaling')\ntext(x, y, pos = 4, labels = BookNamesShorter)\n\n\n#########################################################################################################\n#################################### Network Map #################################################\n#########################################################################################################\n\nlibrary(igraph)\ncorrMatrix_short <- 1 - as.matrix(cosMatrix_short_tfidf)\n#diag(corrMatrix_short)<-0\ngraph<-graph.adjacency(corrMatrix_short,weighted=TRUE,mode=\"lower\", diag = F)\ngraph <- delete.edges(graph, E(graph)[ weight < 0.6 ])\nE(graph)$width <- E(graph)$weight + min(E(graph)$weight) + 3\nplot(graph, vertex.color = 'lightblue', vertex.frame.color = 'white', vertex.label.color = 'black', vertex.label.family = 'sans')\n\n\n\n\n#########################################################################################################\n#################################### Word Frequencies #################################################\n#########################################################################################################\n\n\n\n\nfreq <- colSums(m))\nlength(freq)\nord <- order(freq)\nhist(freq[ord],300)\n\n# most and less common words\nfreq[tail(ord, 20)]\nfreq[head(ord)]\nwordfreq <- m_short[,ord[1745:1731]]\nwrite.csv(wordfreq, 'wordFreq.csv')\nwrite.table(wordfreq, 'clipboard', sep='\\t')\n",
    "created" : 1457981503419.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "25990752",
    "id" : "A57290E0",
    "lastKnownWriteTime" : 1458219461,
    "path" : "C:/Users/Manuel/Desktop/Southampton/Data Mining/Text Analysis/code/CorpusAnalysis.R",
    "project_path" : "CorpusAnalysis.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "type" : "r_source"
}